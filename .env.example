# OpenAI API Key
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Anthropic API Key
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...

# Google API Key
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=...

# Optional: Default model settings
# These values are used when not specified via CLI or code
DEFAULT_MODEL_PROVIDER=openai
DEFAULT_MODEL_NAME=gpt-4o-mini
DEFAULT_TEMPERATURE=0.0

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=false
API_LOG_LEVEL=info

# Session Configuration
SESSION_TTL_HOURS=24
MODEL_CACHE_SIZE=10

# Memory Management Configuration
# Enable/disable conversation summarization (default: true)
MEMORY_ENABLED=true

# Trigger summarization after N messages (default: 20)
MEMORY_TRIGGER_MESSAGE_COUNT=20

# Keep last N messages unsummarized (default: 10)
MEMORY_KEEP_RECENT_COUNT=10

# Provider for summarization (optional, defaults to request provider)
MEMORY_SUMMARIZATION_PROVIDER=openai

# Model for summarization (optional, defaults to gpt-4o-mini for cost efficiency)
MEMORY_SUMMARIZATION_MODEL=gpt-4o-mini

# Temperature for summarization (default: 0.0 for consistency)
MEMORY_SUMMARIZATION_TEMPERATURE=0.0

# Docker Configuration
# When running with Docker Compose, the Chainlit UI connects to the API via the internal network
# FASTAPI_BASE_URL=http://api:8000  (automatically set in docker-compose.yml)

# Phoenix Tracing Configuration
# Enable/disable tracing (default: true)
PHOENIX_ENABLED=true

# Phoenix endpoint (default: http://localhost:6006/v1/traces)
# For Docker: http://phoenix:6006/v1/traces (automatically set in docker-compose.yml)
# For local dev: http://localhost:6006/v1/traces
PHOENIX_ENDPOINT=http://localhost:6006/v1/traces

# Export traces to console for debugging (default: false)
PHOENIX_CONSOLE_EXPORT=false

# ============================================================
# AWS Bedrock Configuration
# ============================================================

# AWS Region for Bedrock (optional, defaults to us-east-1)
# If not set, boto3 will use AWS_REGION or its default region
AWS_DEFAULT_REGION=us-east-1

# Bedrock Model ARNs (comma-separated list)
# Use inference profile ARNs or foundation model ARNs
# Example: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0
BEDROCK_MODEL_ARNS=anthropic.claude-3-5-sonnet-20241022-v2:0,anthropic.claude-3-5-haiku-20241022-v1:0

# AWS Credentials (optional if using AWS CLI or IAM role)
# Only needed if not using 'aws configure' or IAM role
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key

# Note: For local development, run 'aws configure' or 'aws sso login'
# to set up credentials. Boto3 will automatically use them.
